{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from lxml import html\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import OrderedDict\n",
    "import argparse\n",
    "import re\n",
    "import dateutil.parser\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from textatistic import Textatistic\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull articles list from home page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loop through pickle list of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_the_people_j.pkl\", 'rb') as picklefile: \n",
    "    all_the_people = pickle.load(picklefile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://medium.com/@Mapbox',\n",
       " 'https://medium.com/@MediumStaff',\n",
       " 'https://medium.com/@QMlab',\n",
       " 'https://medium.com/@SeattleDataGuy',\n",
       " 'https://medium.com/@Sinergise',\n",
       " 'https://medium.com/@acoustik',\n",
       " 'https://medium.com/@agentdana',\n",
       " 'https://medium.com/@ahmiglarese',\n",
       " 'https://medium.com/@alecburch',\n",
       " 'https://medium.com/@amycurneen',\n",
       " 'https://medium.com/@andrerpena',\n",
       " 'https://medium.com/@awjuliani',\n",
       " 'https://medium.com/@blakelawrence001',\n",
       " 'https://medium.com/@carto',\n",
       " 'https://medium.com/@chad.scherrer',\n",
       " 'https://medium.com/@cholmes',\n",
       " 'https://medium.com/@cyrusrustomji',\n",
       " 'https://medium.com/@dan.allison',\n",
       " 'https://medium.com/@danmccarey',\n",
       " 'https://medium.com/@djmorcode',\n",
       " 'https://medium.com/@ericrodenbeck',\n",
       " 'https://medium.com/@foamspace',\n",
       " 'https://medium.com/@forrestbrazeal',\n",
       " 'https://medium.com/@galen.ballew',\n",
       " 'https://medium.com/@grega.milcinski',\n",
       " 'https://medium.com/@hadleywickham',\n",
       " 'https://medium.com/@ianthro',\n",
       " 'https://medium.com/@james_aka_yale',\n",
       " 'https://medium.com/@jesus.botella',\n",
       " 'https://medium.com/@johaevans',\n",
       " 'https://medium.com/@jonathonmorgan',\n",
       " 'https://medium.com/@krisshaffer',\n",
       " 'https://medium.com/@mappingmashups',\n",
       " 'https://medium.com/@planetlabs',\n",
       " 'https://medium.com/@pranavbadami',\n",
       " 'https://medium.com/@ptrmin91',\n",
       " 'https://medium.com/@rajrsingh',\n",
       " 'https://medium.com/@robsimmon',\n",
       " 'https://medium.com/@samapriyaroy',\n",
       " 'https://medium.com/@scottmlundberg',\n",
       " 'https://medium.com/@simonb83',\n",
       " 'https://medium.com/@stamen',\n",
       " 'https://medium.com/@thisismetis',\n",
       " 'https://medium.com/@tirthajyoti',\n",
       " 'https://medium.com/@tobiasrose',\n",
       " 'https://medium.com/@ultimatist',\n",
       " 'https://medium.com/@virginiacourtdata',\n",
       " 'https://medium.com/@yichiang00',\n",
       " 'https://medium.com/@zimrick',\n",
       " 'https://medium.com/@zupanc.anze'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_the_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://medium.com/@james_aka_yale',\n",
       " 'https://medium.com/@cyrusrustomji',\n",
       " 'https://medium.com/@danmccarey',\n",
       " 'https://medium.com/@andrerpena',\n",
       " 'https://medium.com/@SeattleDataGuy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_sample = list(all_the_people)[-5:]\n",
    "people_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_articles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_home_articles(soup):\n",
    "    article_urls = []\n",
    "    try:\n",
    "        articles = soup.find_all('a', {'data-action':'open-post'})\n",
    "        for item in articles:\n",
    "            if item.text == 'Read moreâ€¦':\n",
    "                url = (item['href'])\n",
    "                url = re.sub('\\?source(.*)','',url)\n",
    "                article_urls.append(url)\n",
    "        return article_urls\n",
    "    except: []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=\"/Users/mayamidzik/tools/chromedriver\")\n",
    "\n",
    "for url in people_sample:\n",
    "    url= url+'/latest'\n",
    "    driver.get(url)\n",
    "    \n",
    "    #scroll to bottom of page\n",
    "    SCROLL_PAUSE_TIME = 0.1\n",
    "    \n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    \n",
    "    #get the html for the page\n",
    "    innerHTML = driver.execute_script(\"return document.body.innerHTML\")\n",
    "    soup = BeautifulSoup(innerHTML,\"lxml\")\n",
    "    \n",
    "    articles = get_home_articles(soup)\n",
    "    master_articles.extend(articles)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://heartbeat.fritz.ai/the-5-computer-vision-techniques-that-will-change-how-you-see-the-world-1ee19334354b',\n",
       " 'https://heartbeat.fritz.ai/the-5-deep-learning-frameworks-every-serious-machine-learner-should-be-familiar-with-93f4d469d24c',\n",
       " 'https://medium.com/the-post-grad-survival-guide/15-systems-thinking-guidelines-to-live-in-a-world-of-uncertainty-26f62b69bee6',\n",
       " 'https://medium.com/@james_aka_yale/15-systems-thinking-guidelines-to-live-in-a-world-of-uncertainty-b07d5a478e6',\n",
       " 'https://medium.com/constraint-drives-creativity/70-pieces-of-wisdom-for-smart-and-driven-college-students-to-enter-the-real-world-c8a391c2eb20',\n",
       " 'https://medium.com/swlh/snapchats-filters-how-computer-vision-recognizes-your-face-9ce536206fa7',\n",
       " 'https://towardsdatascience.com/16-useful-advices-for-aspiring-data-scientists-6da9afa8c72c',\n",
       " 'https://medium.com/@james_aka_yale/70-pieces-of-wisdom-for-smart-and-driven-college-students-to-enter-the-real-world-9fde16e62d65',\n",
       " 'https://medium.com/@james_aka_yale/snapchats-filters-how-computer-vision-recognizes-your-face-9907d6904b91',\n",
       " 'https://towardsdatascience.com/12-useful-things-to-know-about-machine-learning-487d3104e28',\n",
       " 'https://medium.com/maptian/visualizing-the-rule-of-law-c387f162d277',\n",
       " 'https://hi.stamen.com/dc-is-trippin-with-this-new-tool-37a9cf1fecec',\n",
       " 'https://hackernoon.com/debugging-javascript-typescript-node-apps-with-chrome-devtools-vs-code-and-webstorm-97b882aee0ad',\n",
       " 'https://hackernoon.com/taming-anxiety-and-hacking-your-way-into-productivity-1c9258b8380a',\n",
       " 'https://hackernoon.com/a-quick-guide-to-help-you-picking-up-the-best-side-project-to-work-next-30e284e2b2f7',\n",
       " 'https://medium.com/@andrerpena/you-should-read-random-articles-start-at-this-one-2120b6ecbc0c',\n",
       " 'https://hackernoon.com/being-the-ceo-of-your-career-as-a-software-engineer-d29cb2cbb637',\n",
       " 'https://hackernoon.com/want-to-become-a-software-developer-heres-how-to-get-there-55f393aa443c',\n",
       " 'https://hackernoon.com/how-to-get-the-most-out-of-developers-7246e725b368',\n",
       " 'https://hackernoon.com/the-best-way-to-learn-new-technologies-is-by-doing-heres-some-inspiration-6ca144216790',\n",
       " 'https://hackernoon.com/how-do-i-stay-up-to-date-as-a-developer-5ec773e30a82',\n",
       " 'https://medium.com/@andrerpena/i-just-released-react-mde-a-github-style-markdown-editor-for-react-5e4a3f495323',\n",
       " 'https://hackernoon.com/how-to-prioritize-data-science-projects-83fd0f7583c9',\n",
       " 'https://medium.com/@SeattleDataGuy/data-driven-healthcare-optimization-consulting-cd4b31cb8ccc',\n",
       " 'https://medium.com/@SeattleDataGuy/from-data-scientist-to-data-leader-workshop-c6be69698af',\n",
       " 'https://towardsdatascience.com/7-use-cases-for-data-science-and-predictive-analytics-e3616e9331f9',\n",
       " 'https://medium.com/@SeattleDataGuy/data-science-use-case-examples-9a3009b98525',\n",
       " 'https://hackernoon.com/4-must-have-skills-every-data-scientist-should-learn-8ab3f23bc325',\n",
       " 'https://medium.com/@SeattleDataGuy/how-to-grow-as-a-data-scientists-f27c9114fefb',\n",
       " 'https://hackernoon.com/5-things-our-tech-team-learned-about-running-a-nonprofit-dinner-a4e8e7625ecf',\n",
       " 'https://medium.com/@SeattleDataGuy/giving-away-two-free-tickets-to-5-course-dinner-in-seattle-ea84f098632f',\n",
       " 'https://towardsdatascience.com/how-to-develop-a-robust-algorithm-c38e08f32201']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original code for single page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://medium.com/@mmidzik/latest\n"
     ]
    }
   ],
   "source": [
    "#try loading page with selenium, then scrpaing\n",
    "driver = webdriver.Chrome(executable_path=\"/Users/mayamidzik/tools/chromedriver\")\n",
    "url='https://medium.com/@mmidzik/latest'\n",
    "driver.get(url)\n",
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCROLL_PAUSE_TIME = 0.1\n",
    "\n",
    "# Get scroll height\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    # Scroll down to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait to load page\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "    # Calculate new scroll height and compare with last scroll height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "innerHTML = driver.execute_script(\"return document.body.innerHTML\")\n",
    "soup = BeautifulSoup(innerHTML,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gets the href forr all the author's posts from their home page\n",
    "def get_home_articles(soup):\n",
    "    article_urls = []\n",
    "    try:\n",
    "        articles = soup.find_all('a', {'data-action':'open-post'})\n",
    "        for item in articles:\n",
    "            if item.text == 'Read moreâ€¦':\n",
    "                url = (item['href'])\n",
    "                url = re.sub('\\?source(.*)','',url)\n",
    "                article_urls.append(url)\n",
    "        return article_urls\n",
    "    except: []\n",
    "\n",
    "get_home_articles(soup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go into a specific article and get necessary metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start here: https://medium.com/data-for-democracy/one-year-of-data-for-democracy-312ab48eecfd\n",
    "for_DfD= 'https://medium.com/data-for-democracy/one-year-of-data-for-democracy-312ab48eecfd'\n",
    "no_DfD= 'https://medium.com/@jonathonmorgan/introducing-new-knowledge-defending-public-discourse-c89f59630c3a'\n",
    "tester = 'https://medium.com/sentinel-hub/improving-cloud-detection-with-machine-learning-c09dc5d7cf13'\n",
    "driver.get('https://blog.mapbox.com/patagonias-dam-good-map-680d9926101f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "articleHTML = driver.execute_script(\"return document.body.innerHTML\")\n",
    "articlesoup = BeautifulSoup(articleHTML,\"lxml\")\n",
    "articlesoup;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the article is associated with a publication\n",
    "def check_pub(soup):\n",
    "    if soup.find_all('a',{'class':'js-collectionLogoOrName'}):\n",
    "        return 1\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_writer\n",
    "\n",
    "def get_author(soup):\n",
    "    author_url = soup.find('a',{'data-action-source':'post_header_lockup'})\n",
    "    if author_url:\n",
    "        author_url = author_url['href']\n",
    "        author_url = re.sub('\\?source(.*)','',author_url)\n",
    "        return author_url\n",
    "    else: return numpy.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the date and time of the article:\n",
    "#should write an exception in case time is missing\n",
    "def get_datetime(soup):\n",
    "    published = soup.find('time')\n",
    "    if published: \n",
    "        return published['datetime']\n",
    "    else: return numpy.nan\n",
    "\n",
    "def get_date(soup):\n",
    "    published = soup.find('time')\n",
    "    if published: \n",
    "        return published.text\n",
    "    else: return numpy.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the reading time for the article\n",
    "\n",
    "def get_reading_time(soup):\n",
    "    reading = soup.find('span',{'class':'readingTime'})\n",
    "    if reading:\n",
    "        reading = reading['title']\n",
    "        #reading = list(filter(str.isdigit, reading))\n",
    "        #return int(''.join(reading))\n",
    "        return reading\n",
    "    else: return numpy.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the tags for the article\n",
    "def get_tags(soup):\n",
    "    tag_list = []\n",
    "    tags = articlesoup.find('ul',{'class':'tags tags--postTags tags--borderless'})\n",
    "    if tags:\n",
    "        tags = tags.find_all('li')\n",
    "        for tag in tags:\n",
    "            tag_list.append(tag.text)\n",
    "    return tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get claps\n",
    "def get_claps(soup):\n",
    "    claps = articlesoup.find('button',{'data-action':'show-recommends'})\n",
    "    if claps: return int(claps.text)\n",
    "    else: return numpy.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://blog.mapbox.com/patagonias-dam-good-map-680d9926101f': {'author': 'https://blog.mapbox.com/@Mapbox',\n",
       "  'claps': 1,\n",
       "  'date': 'Apr 18',\n",
       "  'datetime': '2018-04-18T20:20:20.291Z',\n",
       "  'publisher': 1,\n",
       "  'reading_time': '2 min read'}}"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_traits = {}\n",
    "currentURL =  driver.current_url\n",
    "article_traits[currentURL] = {}\n",
    "article_traits\n",
    "\n",
    "def write_all_traits(soup):\n",
    "    article_traits[currentURL] = {'publisher': check_pub(articlesoup)}\n",
    "    article_traits[currentURL].update({'author': get_author(articlesoup)})\n",
    "    article_traits[currentURL].update({'datetime': get_datetime(articlesoup)})\n",
    "    article_traits[currentURL].update({'date': get_date(articlesoup)})\n",
    "    article_traits[currentURL].update({'reading_time': get_reading_time(articlesoup)})\n",
    "    article_traits[currentURL].update({'claps': get_claps(articlesoup)})\n",
    "    return article_traits\n",
    "\n",
    "write_all_traits(articlesoup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flesch': 55.737517838939894, 'images': 5, 'sentences': 9, 'words': 216}"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all attributes around the article text\n",
    "article_text_traits= {}\n",
    "\n",
    "def get_text_traits(soup):\n",
    "    \n",
    "    #get the number of images and add to dictionary\n",
    "    article_images = soup.find_all('img',{'class' : 'progressiveMedia-image js-progressiveMedia-image'})\n",
    "    if article_images:\n",
    "        #add to dictionary\n",
    "        article_text_traits['images'] = len(article_images)\n",
    "    else: article_text_traits['images'] = np.nan\n",
    "    \n",
    "    #get the tota; text block for the article\n",
    "    article_text = articlesoup.find_all('p')\n",
    "    total_text = ''\n",
    "    if article_text:\n",
    "        for text in article_text:\n",
    "            total_text+=(text.text)\n",
    "            \n",
    "        #get total word count\n",
    "        article_text_traits['words'] = len(total_text.split())\n",
    "        \n",
    "        #get sentence count\n",
    "        article_text_traits['sentences'] = total_text.count('.')\n",
    "        \n",
    "        #get flesch readability\n",
    "        try:\n",
    "            s = Textatistic(total_text)\n",
    "            article_text_traits['flesch'] = s.flesch_score\n",
    "        except: article_text_traits['flesch'] = np.nan\n",
    "            \n",
    "    else:\n",
    "        article_text_traits['words'] = np.nan\n",
    "        article_text_traits['sentences'] = np.nan\n",
    "        article_text_traits['flesch'] = np.nan\n",
    "        \n",
    "\n",
    "get_text_traits(articlesoup)\n",
    "article_text_traits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://blog.mapbox.com/patagonias-dam-good-map-680d9926101f': {'author': 'https://blog.mapbox.com/@Mapbox',\n",
       "  'claps': 1,\n",
       "  'date': 'Apr 18',\n",
       "  'datetime': '2018-04-18T20:20:20.291Z',\n",
       "  'flesch': 55.737517838939894,\n",
       "  'images': 5,\n",
       "  'publisher': 1,\n",
       "  'reading_time': '2 min read',\n",
       "  'sentences': 9,\n",
       "  'words': 216}}"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_traits[currentURL].update(article_text_traits)\n",
    "article_traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>date</th>\n",
       "      <th>datetime</th>\n",
       "      <th>flesch</th>\n",
       "      <th>images</th>\n",
       "      <th>publisher</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://blog.mapbox.com/patagonias-dam-good-ma...</td>\n",
       "      <td>https://blog.mapbox.com/@Mapbox</td>\n",
       "      <td>1</td>\n",
       "      <td>Apr 18</td>\n",
       "      <td>2018-04-18T20:20:20.291Z</td>\n",
       "      <td>55.7375</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2 min read</td>\n",
       "      <td>9</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://blog.mapbox.com/patagonias-dam-good-ma...   \n",
       "\n",
       "                            author claps    date                  datetime  \\\n",
       "0  https://blog.mapbox.com/@Mapbox     1  Apr 18  2018-04-18T20:20:20.291Z   \n",
       "\n",
       "    flesch images publisher reading_time sentences words  \n",
       "0  55.7375      5         1   2 min read         9   216  "
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write to a dataframe\n",
    "df = pd.DataFrame.from_dict(article_traits).T\n",
    "df.reset_index(level=0, inplace=True)\n",
    "df['index'] = df\n",
    "df.rename(columns = {'index':'url'},inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
